{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e4fc49b-9ce0-453c-8e5f-ce772dd7fc4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Importing the modules that we'll need for this exercise\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from requests_html import AsyncHTMLSession\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0eee56f-bd40-4b9f-8ad0-29cd5c24b4fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %pip install selenium ### I used this code to install selenium on my cluster. \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e1fa16d-6771-4fb4-a069-918e51a45cf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The hard coded list of URLs\n",
    "urls = [\n",
    "    \"https://www.usnews.com/best-colleges/washington-university-in-st-louis-2520\",\n",
    "    \"https://www.usnews.com/best-colleges/saint-louis-university-2506\",\n",
    "    \"https://www.usnews.com/best-colleges/umsl-2519\",\n",
    "    \"https://www.usnews.com/best-colleges/webster-university-2521\"\n",
    "]\n",
    "\n",
    "# Adding headers to help with scraping. (I used AI, specifically Claude, to help me with this as USNews was giving me some scraping errors)\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Upgrade-Insecure-Requests': '1'\n",
    "}\n",
    "\n",
    "\n",
    "# Store all the scraped data\n",
    "scraped_data = []\n",
    "\n",
    "session = HTMLSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55bb11fd-9223-410f-8c76-ee189bb9b03f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## WHAT FOLLOWS IS DEFUCT CODE ONLY FOR REFERENCE\n",
    "###### This next block is a defunct codeset. Upon my work, I learned the US News loads their pages dynamically, making scraping using requests unusable. I left this code in here for visability into my overall process and what prompted me to work through another avenue. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16860fc2-231b-42e7-8a2f-6b155afed4eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "### This is a defunct codeset. Upon my work, I learned the US News loads their pages dynamically, making scraping using requests unusable. I continue my \n",
    "\n",
    "\n",
    "# Scraping and parsing the data into the scraped_data list. \n",
    "for i, url in enumerate(urls):\n",
    "    try: # scraping code\n",
    "        print(f\"Scraping {i+1}/{len(urls)}: {url}\")\n",
    "\n",
    "        response = requests.get(url, headers=headers, timeout=60)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find the specific population element within the noted class. \n",
    "        element = soup.find('p', class_='MuiTypography-root MuiTypography-body1 css-1udwrrf')\n",
    "\n",
    "        if element: \n",
    "            number = element.text.strip() # Gets the population number reported on the site. \n",
    "            number_clean = int(number.replace(',','')) # Removing the comma and turning the scraped element text into a number. \n",
    "        else: \n",
    "            number = None\n",
    "            print(f\" !! Element not found on {URL}\")\n",
    "\n",
    "        scraped_data.append({\n",
    "            'url': url, \n",
    "            'population': number_clean\n",
    "        })\n",
    "\n",
    "        print(f\" Extracted: {number} from {url}\")\n",
    "\n",
    "        # adding a delay between requests\n",
    "        time.sleep(3)\n",
    "\n",
    "    except Exception as e: # exception handling\n",
    "        print(f\" x Error with {url}: {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "494695da-760f-4adc-8caa-7056ed937785",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fix SyntaxError in Selenium scraping code"
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "# Configure Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "\n",
    "# ChromeDriverManager automatically downloads the right driver\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=chrome_options\n",
    ")\n",
    "\n",
    "try:\n",
    "    for i, url in enumerate(urls):\n",
    "        try: \n",
    "            print(f\"Scraping {i+1}/{len(urls)}: {url}\")\n",
    "\n",
    "            driver.get(url)\n",
    "\n",
    "            # wait for the element to load. \n",
    "            element = WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((\n",
    "                    By.CSS_SELECTOR,\n",
    "                    \"p.MuiTypography-root.MuiTypography-body1.css-1udwrrf\"\n",
    "                ))\n",
    "            )\n",
    "\n",
    "            number = element.text.strip()\n",
    "            number_clean = int(number.replace(',',''))\n",
    "            \n",
    "            print(f\" Extracted: {number} from {url}\")\n",
    "\n",
    "            scraped_data.append({'url': url, 'students': number_clean})\n",
    "\n",
    "            time.sleep(2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {url}: {e}\")\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fd144bd-146e-4be1-8e99-8dd29d75cf92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "for i, url in enumerate(urls):\n",
    "    try:\n",
    "        print(f\"Scraping {i+1}/{len(urls)}: {url}\")\n",
    "        \n",
    "        response = session.get(url)\n",
    "        \n",
    "        # Render JavaScript (this may take a moment)\n",
    "        response.html.render(timeout=20)\n",
    "        \n",
    "        # Find the element\n",
    "        elements = response.html.find('p.MuiTypography-root.MuiTypography-body1.css-1udwrrf')\n",
    "        \n",
    "        if elements:\n",
    "            number = elements[0].text.strip()\n",
    "            print(f\"  ✓ Extracted: {number}\")\n",
    "        else:\n",
    "            number = None\n",
    "            print(f\"  ⚠ Element not found\")\n",
    "            \n",
    "        scraped_data.append({'url': url, 'value': number})\n",
    "        \n",
    "        time.sleep(2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a2f6693-ee84-4f6c-be8b-b88d495b5c87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "async def scrape_url(session, url, index, total):\n",
    "    try:\n",
    "        print(f\"Scraping {index}/{total}: {url}\")\n",
    "        \n",
    "        response = await session.get(url)\n",
    "        \n",
    "        # Render JavaScript\n",
    "        await response.html.arender(timeout=20)\n",
    "        \n",
    "        # Find the element\n",
    "        elements = response.html.find('p.MuiTypography-root.MuiTypography-body1.css-1udwrrf')\n",
    "        \n",
    "        if elements:\n",
    "            number = elements[0].text.strip()\n",
    "            print(f\"  ✓ Extracted: {number}\")\n",
    "        else:\n",
    "            number = None\n",
    "            print(f\"  ⚠ Element not found\")\n",
    "            \n",
    "        return {'url': url, 'value': number}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error: {e}\")\n",
    "        return {'url': url, 'value': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff884662-05ac-443d-bae0-2f40cc67fa9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "async def scrape_all():\n",
    "    all_data = []\n",
    "    asession = AsyncHTMLSession()\n",
    "    \n",
    "    for i, url in enumerate(urls, 1):\n",
    "        result = await scrape_url(asession, url, i, len(urls))\n",
    "        all_data.append(result)\n",
    "        await asyncio.sleep(2)  # Delay between requests\n",
    "    \n",
    "    await asession.close()\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b11bc7bd-fd98-425c-8ab0-69f0d5680c27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use the existing event loop in Databricks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "all_data = asyncio.get_event_loop().run_until_complete(scrape_all())"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "selenium",
     "requests-html"
    ],
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "test_exercise04.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
